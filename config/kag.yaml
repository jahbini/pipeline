# ============================================================
# Celarien KAG Pipeline â€” DEFAULT CONFIGURATION
# ============================================================
# No hidden defaults. Every step parameter lives here.
# All scripts expect these keys and only these keys.
# ============================================================

runu
  # Output structure (memo + regex will persist automatically)
  output_dir: out
  data_dir: data
  eval_dir: eval_out
  # These are file paths relative to CWD; we do not inject defaults.
  stories: /Volumes/bigbig/theaiguy/testPipeline/data/kag_train.jsonl       # your story segments jsonl
  emotions: /Volumes/bigbig/theaiguy/testPipeline/data/kag_examples.jsonl     # your emotions jsonl
  mergedStories: data/merged_segments.jsonl         # KAG training jsonl (for LoRA)
  mergedStories2: loraLand/valid.jsonl          # KAG training jsonl (for LoRA)
  loraLand: loraLand

  # core dataset files
  story_segments: data/story_segments.jsonl
  kag_emotions: data/kag_emotions.jsonl

  # merged + enriched training set
  merged_segments: data/merged_segments.jsonl
  kag_examples: loraLand
  train_file: loraLand/train.jsonl
  valid_file: loraLand/valid.jsonl

  # standard artifact definitions
  contract: data_contract.json
  catalog: data_catalog.json
  report: data_report.json
  prompt_policy: prompt_policy.json
  experiments_csv: experiments.csv
  artifacts: artifacts.json            # written under out/
  tokmeta: tokenizer_meta.json

  # the single base model to tune
  model: microsoft/Phi-3-mini-4k-instruct

# ------------------------------------------------------------
# Step Configurations
# ------------------------------------------------------------

manifest:
  run: scripts/full/manifest.coffee
  seed: 7
  desc: "Initialize memo with experiment.yaml"

# ------------------------------------------------------------
load_story_segments:
  input: data/story_segments.jsonl
  output: data/story_segments.jsonl

load_kag_emotions:
  input: data/kag_emotions.jsonl
  output: data/merged_segments.jsonl

# ------------------------------------------------------------
merge_segments_with_kag:
  story_key: data/story_segments.jsonl
  kag_key: data/kag_emotions.jsonl
  output: data/merged_segments.jsonl

kag_merge:
    run: scripts/full/merge.coffee
# ------------------------------------------------------------
prepare_experiments:
  run: scripts/full/prepare_experiments.coffee
  epochs: 1
  batch_size: 1
  grad_accum: 8
  max_seq_length: 768
  learning_rate: 1.0e-4
  bf16: true
  iters_override: 400        # short runs for iterative development
  output: experiments.csv

prepare_prompts:
  run: scripts/full/prepare_prompts.coffee

# ------------------------------------------------------------
prepare_data:
  # validates kag_examples.jsonl
  input: data/kag_examples.jsonl
  output: data/data_report.json

# ------------------------------------------------------------
register:
  # nothing to configure here except artifact paths
  artifacts: out/artifacts.json

# ------------------------------------------------------------
train:
  run: scripts/full/train.coffee
  dry_run: false
  only_model_id: ""         # blank = use run.model
  only_row: "None"          # pipeline always has 1 row
  steps_per_report: 50
  steps_per_eval: 50
  val_batches: 0
  experiments_csv: experiments.csv

# ------------------------------------------------------------
fuse:
  do_fuse: true
  q_bits: 4
  q_group: 32
  dtype: float16
  dry_run: false

# ------------------------------------------------------------
snapshot:
  prompts:
    - "Share a brief thought."
    - "What emotion hides beneath struggle?"
  max_new: 64

# ------------------------------------------------------------
examination:
  prompts:
    - "Share an important thought."
  max_new_short: 64
  max_new_long: 128
  ablations: ablations

# ------------------------------------------------------------
# Optional disabled step
extract_md_for_voice:
  desc: "Disabled"
  depends_on: [never]
